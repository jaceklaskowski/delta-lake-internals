# VacuumTableCommand

`VacuumTableCommand` is a runnable command ([Spark SQL]({{ book.spark_sql }}/logical-operators/RunnableCommand)) for [VACUUM](index.md) SQL command.

## Creating Instance

`VacuumTableCommand` takes the following to be created:

* <span id="path"> Path
* <span id="table"> `TableIdentifier`
* <span id="horizonHours"> Optional Horizon Hours
* <span id="dryRun"> `dryRun` flag

`VacuumTableCommand` [requires](#run) that either the [table](#table) or the [path](#path) is defined and it is the root directory of a delta table. Partition directories are not supported.

`VacuumTableCommand` is createdÂ when:

* `DeltaSqlAstBuilder` is requested to [parse VACUUM SQL command](../../sql/DeltaSqlAstBuilder.md#visitVacuumTable)

## <span id="run"> Executing Command

```scala
run(
  sparkSession: SparkSession): Seq[Row]
```

`run` is part of the `RunnableCommand` ([Spark SQL]({{ book.spark_sql }}/logical-operators/RunnableCommand#run)) abstraction.

`run` takes the path to vacuum (either the [table](#table) or the [path](#path)) and [finds the root directory of the delta table](../../DeltaTableUtils.md#findDeltaTableRoot).

`run` creates a [DeltaLog](../../DeltaLog.md#forTable) instance for the delta table and [gc](VacuumCommand.md#gc) it (passing in the `DeltaLog` instance, the [dryRun](#dryRun) and the [horizonHours](#horizonHours) options).

`run` throws an `AnalysisException` when executed for a non-root directory of a delta table:

```text
Please provide the base path ([baseDeltaPath]) when Vacuuming Delta tables. Vacuuming specific partitions is currently not supported.
```

`run` throws an `AnalysisException` when executed for a `DeltaLog` with the snapshot version being `-1`:

```text
[deltaTableIdentifier] is not a Delta table. VACUUM is only supported for Delta tables.
```

## <span id="output"> Output Schema

The output schema of `VacuumTableCommand` is a single `path` column (of type `StringType`).
