# DeltaSQLConf

`DeltaSQLConf` contains [spark.databricks.delta](index.md#spark.databricks.delta)-prefixed configuration properties to configure behaviour of Delta Lake.

## checkpoint.partSize { #DELTA_CHECKPOINT_PART_SIZE }

[spark.databricks.delta.checkpoint.partSize](index.md#checkpoint.partSize)

## merge.materializeSource { #DELTA_COLLECT_STATS_USING_TABLE_SCHEMA }

[spark.databricks.delta.merge.materializeSource](index.md#merge.materializeSource)

## merge.materializeSource.rddStorageLevel { #MERGE_MATERIALIZE_SOURCE_RDD_STORAGE_LEVEL }

[spark.databricks.delta.merge.materializeSource.rddStorageLevel](index.md#merge.materializeSource.rddStorageLevel)

## merge.materializeSource.rddStorageLevelRetry { #MERGE_MATERIALIZE_SOURCE_RDD_STORAGE_LEVEL_RETRY }

[spark.databricks.delta.merge.materializeSource.rddStorageLevelRetry](index.md#merge.materializeSource.rddStorageLevelRetry)

## merge.materializeSource.rddStorageLevelRetry { #MERGE_MATERIALIZE_SOURCE_RDD_STORAGE_LEVEL_RETRY }

[spark.databricks.delta.merge.materializeSource.rddStorageLevelRetry](index.md#merge.materializeSource.rddStorageLevelRetry)

## stats.collect { #DELTA_COLLECT_STATS }

[spark.databricks.delta.stats.collect](index.md#stats.collect)

## stats.collect.using.tableSchema { #MERGE_MATERIALIZE_SOURCE }

[spark.databricks.delta.stats.collect.using.tableSchema](index.md#stats.collect.using.tableSchema)
